{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Step 1: Get data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9730de32cf6a82a2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  anime_id  rating\n",
      "0        1        20      -1\n",
      "1        1        24      -1\n",
      "2        1        79      -1\n",
      "3        1       226      -1\n",
      "4        1       241      -1\n",
      "   anime_id                              name  \\\n",
      "0     32281                    Kimi no Na wa.   \n",
      "1      5114  Fullmetal Alchemist: Brotherhood   \n",
      "2     28977                          GintamaÂ°   \n",
      "3      9253                       Steins;Gate   \n",
      "4      9969                     Gintama&#039;   \n",
      "\n",
      "                                               genre   type episodes  rating  \\\n",
      "0               Drama, Romance, School, Supernatural  Movie        1    9.37   \n",
      "1  Action, Adventure, Drama, Fantasy, Magic, Mili...     TV       64    9.26   \n",
      "2  Action, Comedy, Historical, Parody, Samurai, S...     TV       51    9.25   \n",
      "3                                   Sci-Fi, Thriller     TV       24    9.17   \n",
      "4  Action, Comedy, Historical, Parody, Samurai, S...     TV       51    9.16   \n",
      "\n",
      "   members  \n",
      "0   200630  \n",
      "1   793665  \n",
      "2   114262  \n",
      "3   673572  \n",
      "4   151266  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "users = pd.read_csv('rating.csv')\n",
    "anime = pd.read_csv('anime.csv')\n",
    "print(users.head())\n",
    "print(anime.head())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T22:27:52.317063Z",
     "start_time": "2025-02-27T22:27:50.972312Z"
    }
   },
   "id": "42fc812d8cd91ba",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T22:27:52.323222Z",
     "start_time": "2025-02-27T22:27:52.317255Z"
    }
   },
   "id": "d2434fb700172d37",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# just crop data to be first 500,000\n",
    "users = users[:1000000]\n",
    "train_users, test_users = train_test_split(users, test_size=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T22:27:52.431930Z",
     "start_time": "2025-02-27T22:27:52.334518Z"
    }
   },
   "id": "cfb10f593eb47e6",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# get some useful info from users\n",
    "users = set()\n",
    "animes = set()\n",
    "usersPerAnime = defaultdict(set) # Maps an anime to the user who rated it\n",
    "animesPerUser = defaultdict(set) # Maps a user to the anime that they rated\n",
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerAnime = defaultdict(list)\n",
    "ratingDict = {} # To retrieve a rating for a specific user/item pair\n",
    "\n",
    "# item = book in this case\n",
    "for d in users:\n",
    "    review = d['review_id']\n",
    "    user = d['user_id']\n",
    "    users.add(user)\n",
    "    anime = d['anime_id']\n",
    "    animes.add(anime)\n",
    "    usersPerAnime[anime].add(user)\n",
    "    animesPerUser[user].add(anime)\n",
    "    reviewsPerAnime[anime].append(d)\n",
    "    reviewsPerUser[user].append(d)\n",
    "    ratingDict[(user,anime)] = d['rating']\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T22:27:52.432628Z",
     "start_time": "2025-02-27T22:27:52.407528Z"
    }
   },
   "id": "162a471a6e0b6b52",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Load from pickle files\n",
    "# with open('train_users.pkl', 'rb') as f:\n",
    "#     train_users = pickle.load(f)\n",
    "# \n",
    "# with open('test_users.pkl', 'rb') as f:\n",
    "#     test_users = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T22:27:52.433103Z",
     "start_time": "2025-02-27T22:27:52.410858Z"
    }
   },
   "id": "61717dd15f76c324",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set : 900000, test set people: 100000\n",
      "        user_id  anime_id  rating\n",
      "156220     1551     30307       8\n",
      "58622       611      1896      -1\n",
      "100607     1034     15809      10\n",
      "530426     5331      4720       8\n",
      "459645     4744      5114      10\n"
     ]
    }
   ],
   "source": [
    "# train_users = pd.DataFrame(columns=users.columns)\n",
    "# test_users = pd.DataFrame(columns=users.columns)\n",
    "# \n",
    "# prev_user = None\n",
    "# count = 0\n",
    "# \n",
    "# for idx, row in users.iterrows():\n",
    "#     current_user = row['user_id']\n",
    "#     \n",
    "#     # Check if different user, restart count\n",
    "#     if prev_user != current_user:\n",
    "#         count = 0\n",
    "#         prev_user = current_user\n",
    "#     \n",
    "#     # Increment count\n",
    "#     count += 1\n",
    "#     \n",
    "#     # Every 5th item (20%) goes to test set\n",
    "#     if count % 5 == 0:\n",
    "#         test_users_alt = pd.concat([test_users, pd.DataFrame([row])]) \n",
    "#     else:\n",
    "#         train_users_alt = pd.concat([train_users, pd.DataFrame([row])])\n",
    "# \n",
    "# # Reset indices\n",
    "# train_users_alt = train_users.reset_index(drop=True)\n",
    "# test_users_alt = test_users.reset_index(drop=True)\n",
    "# \n",
    "# # Random sampling to exactly 300,000 rows\n",
    "# if len(train_users) > 300000:\n",
    "#     train_users = train_users.sample(n=300000, random_state=42).reset_index(drop=True)\n",
    "#     \n",
    "# if len(test_users) > 10000:\n",
    "#     test_users = test_users.sample(n=300000, random_state=42).reset_index(drop=True)\n",
    "# \n",
    "# \n",
    "# # Print the sizes of the datasets\n",
    "print(f\"train set : {len(train_users)}, test set people: {len(test_users)}\")\n",
    "print(test_users.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T22:27:52.433893Z",
     "start_time": "2025-02-27T22:27:52.420238Z"
    }
   },
   "id": "9538b1e76ea76bc1",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Save train and test dataframes\n",
    "# with open('train_users.pkl', 'wb') as f:\n",
    "#     pickle.dump(train_users, f)\n",
    "# \n",
    "# with open('test_users.pkl', 'wb') as f:\n",
    "#     pickle.dump(test_users, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T22:27:52.434228Z",
     "start_time": "2025-02-27T22:27:52.425222Z"
    }
   },
   "id": "ddc8ae81396e9629",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# what is the rating scale? \n",
    "# print('max rating is ', max(train_users['rating'])) # its 10\n",
    "# print('min rating is ', min(train_users['rating'])) # its -1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T22:27:52.456145Z",
     "start_time": "2025-02-27T22:27:52.429556Z"
    }
   },
   "id": "8083d1a335eb6ca2",
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now create baseline model for recommendation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b25c92c141b4ad1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, SVDpp\n",
    "from surprise.model_selection import train_test_split, cross_validate\n",
    "from surprise import accuracy\n",
    "from itertools import combinations\n",
    "from scipy.spatial.distance import cosine"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T22:27:52.458080Z",
     "start_time": "2025-02-27T22:27:52.436708Z"
    }
   },
   "id": "194a6825cde77c02",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(-1, 10))  # Assuming ratings from 1 to 5\n",
    "train_data = Dataset.load_from_df(train_users, reader)  # Assuming ratings_df is your ratings dataframe\n",
    "trainset = train_data.build_full_trainset()\n",
    "test_data = Dataset.load_from_df(test_users, reader)\n",
    "svdpp = SVDpp(n_factors=3, n_epochs=20, lr_all=0.007, reg_all=0.02, verbose=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T22:27:54.166948Z",
     "start_time": "2025-02-27T22:27:52.500725Z"
    }
   },
   "id": "4f4d9fe108acf580",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n"
     ]
    },
    {
     "data": {
      "text/plain": "<surprise.prediction_algorithms.matrix_factorization.SVDpp at 0x107a62d60>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svdpp.fit(trainset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T22:29:14.670840Z",
     "start_time": "2025-02-27T22:27:54.160215Z"
    }
   },
   "id": "6fe3f5bfc44f4248",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'test_rmse': array([2.50515915, 2.49598847, 2.51622981, 2.52748539, 2.60830336]),\n 'test_mae': array([1.69521731, 1.68843092, 1.70955328, 1.7036978 , 1.77628598]),\n 'fit_time': (0.8848099708557129,\n  0.8438119888305664,\n  0.8538579940795898,\n  0.8514468669891357,\n  0.8563671112060547),\n 'test_time': (0.4562990665435791,\n  0.4413421154022217,\n  0.4351181983947754,\n  0.4782261848449707,\n  0.44852495193481445)}"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import KFold\n",
    "\n",
    "kf = KFold(random_state=0)  # folds will be the same for all algorithms.\n",
    "cross_validate(svdpp, test_data, [\"rmse\",\"mae\"],kf)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T22:29:22.727516Z",
     "start_time": "2025-02-27T22:29:14.700883Z"
    }
   },
   "id": "ce21c4d5038cb146",
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we need to test diversity"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45a39d0fcc72b212"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import jaccard_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    \"\"\"Compute Jaccard similarity between two sets.\"\"\"\n",
    "    return len(set1 & set2) / len(set1 | set2) if len(set1 | set2) > 0 else 0\n",
    "\n",
    "\n",
    "def calculate_diversity(predictions, anime_df, embedding_matrix, popularity_dict):\n",
    "    \"\"\"Calculate an enhanced diversity score for a list of anime recommendations.\"\"\"\n",
    "    \n",
    "    anime_ids = predictions  # List of recommended anime IDs\n",
    "    genre_sets = []\n",
    "    latent_vectors = []\n",
    "    popularity_scores = []\n",
    "\n",
    "    for anime_id in anime_ids:\n",
    "        genre_str = anime_df.loc[anime_df['anime_id'] == anime_id, 'genre']\n",
    "        if not genre_str.empty:\n",
    "            genre_sets.append(set(genre_str.values[0].split(', ')))\n",
    "        else:\n",
    "            genre_sets.append(set())  # Handle missing genres\n",
    "\n",
    "        # Retrieve latent representation from embeddings (if available)\n",
    "        if anime_id in embedding_matrix:\n",
    "            latent_vectors.append(embedding_matrix[anime_id])\n",
    "        \n",
    "        # Retrieve popularity score (if available)\n",
    "        popularity_scores.append(popularity_dict.get(anime_id, 0.5))  # Default to 0.5 if missing\n",
    "\n",
    "    # Compute pairwise genre similarities\n",
    "    genre_similarities = [jaccard_similarity(g1, g2) for g1, g2 in combinations(genre_sets, 2)]\n",
    "    \n",
    "    # Compute pairwise embedding (latent space) dissimilarities\n",
    "    latent_dissimilarities = [1 - cosine(v1, v2) for v1, v2 in combinations(latent_vectors, 2) if v1 is not None and v2 is not None]\n",
    "\n",
    "    # Compute average popularity score (higher means more mainstream recommendations)\n",
    "    avg_popularity = sum(popularity_scores) / len(popularity_scores)\n",
    "\n",
    "    # Calculate final diversity components\n",
    "    genre_diversity = 1 - (sum(genre_similarities) / len(genre_similarities)) if genre_similarities else 1\n",
    "    latent_diversity = sum(latent_dissimilarities) / len(latent_dissimilarities) if latent_dissimilarities else 1\n",
    "    long_tail_penalty = 1 - avg_popularity  # Encourages recommending lesser-known anime\n",
    "\n",
    "    # Weighted combination\n",
    "    diversity_score = (0.4 * genre_diversity) + (0.4 * latent_diversity) + (0.2 * long_tail_penalty)\n",
    "\n",
    "    return diversity_score\n",
    "\n",
    "\n",
    "    # Compute pairwise genre similarities\n",
    "    similarities = [jaccard_similarity(g1, g2) for g1, g2 in combinations(genre_sets, 2)]\n",
    "\n",
    "    # Diversity is 1 - average similarity\n",
    "    diversity_score = 1 - (sum(similarities) / len(similarities)) if similarities else 1\n",
    "    return diversity_score\n",
    "\n",
    "\n",
    "def get_recommendations_with_diversity(test_users, svdpp, anime_df, n=5):\n",
    "    \"\"\"\n",
    "    Get anime recommendations and calculate diversity scores.\n",
    "    \n",
    "    Args:\n",
    "        test_users: DataFrame with user information\n",
    "        svdpp: Trained SVD++ model\n",
    "        anime_df: DataFrame with anime information\n",
    "        n: Number of top recommendations to consider\n",
    "        \n",
    "    Returns:\n",
    "        float: Average diversity score across all test users\n",
    "    \"\"\"\n",
    "    diversity_scores = []\n",
    "    \n",
    "    for _, user in test_users.iterrows():\n",
    "        uid = int(user[\"user_id\"])\n",
    "        \n",
    "        # Find similar users and candidate anime\n",
    "        similar_users = get_similar_users(uid, k=10)\n",
    "        candidate_anime = get_candidate_anime(similar_users)\n",
    "        \n",
    "        if not candidate_anime:\n",
    "            continue\n",
    "            \n",
    "        # Get predictions for candidate anime only\n",
    "        predictions = []\n",
    "        for iid in candidate_anime:\n",
    "            pred = svdpp.predict(uid, int(iid))\n",
    "            predictions.append((iid, pred.est))\n",
    "        \n",
    "        # Get top N recommendations\n",
    "        top_n_anime = [iid for iid, _ in sorted(predictions, key=lambda x: x[1], reverse=True)[:n]]\n",
    "        \n",
    "        # Calculate diversity score for this user's recommendations\n",
    "        diversity_score = calculate_diversity(top_n_anime, anime_df)\n",
    "        diversity_scores.append(diversity_score)\n",
    "    \n",
    "    # Return average diversity\n",
    "    return sum(diversity_scores) / len(diversity_scores) if diversity_scores else 0\n",
    "\n",
    "\n",
    "def get_similar_users(user_id, k=10):\n",
    "    \"\"\"Find k most similar users based on Jaccard similarity.\"\"\"\n",
    "    if user_id not in animesPerUser:\n",
    "        return []\n",
    "    \n",
    "    user_watched = animesPerUser[user_id]\n",
    "    similarities = {}\n",
    "\n",
    "    for other_user, other_watched in animesPerUser.items():\n",
    "        if other_user == user_id:\n",
    "            continue\n",
    "        similarities[other_user] = jaccard_similarity(user_watched, other_watched)\n",
    "    \n",
    "    # Return top k similar users\n",
    "    return [uid for uid, _ in sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:k]]\n",
    "\n",
    "\n",
    "def get_candidate_anime(similar_users):\n",
    "    \"\"\"Get anime watched by similar users.\"\"\"\n",
    "    if not similar_users:\n",
    "        return []\n",
    "    \n",
    "    candidate_anime = set()\n",
    "    for user in similar_users:\n",
    "        candidate_anime.update(animesPerUser[user])\n",
    "    \n",
    "    return list(candidate_anime)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T22:29:22.728399Z",
     "start_time": "2025-02-27T22:29:22.706978Z"
    }
   },
   "id": "415362b2af2843bc",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Diversity Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Run recommendations and calculate diversity score\n",
    "avg_diversity = get_recommendations_with_diversity(test_users, svdpp, anime, n=5)\n",
    "\n",
    "# Print the final diversity score\n",
    "print(f\"Average Diversity Score: {float(avg_diversity)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T22:29:24.674611Z",
     "start_time": "2025-02-27T22:29:22.781376Z"
    }
   },
   "id": "a0202f75a44c8c8a",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T22:29:24.675097Z",
     "start_time": "2025-02-27T22:29:24.672Z"
    }
   },
   "id": "f40211b08a888bb0",
   "execution_count": 54
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
